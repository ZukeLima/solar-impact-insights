# ğŸŒ Solar Impact Insights

Complete system for analysis and prediction of Solar Energetic Particle (SEP) events using Docker, PostgreSQL, and FastAPI.

## ğŸš€ Features

### ğŸ“Š **Multiple Dashboards**
- **Main Web Dashboard**: Modern interface with interactive charts
- **Streamlit Analytics**: Advanced analysis and data exploration
- **Grafana Monitoring**: Real-time monitoring with alerts

### ğŸ”¬ **Advanced Analytics**
- **Data Collection**: Integration with solar and atmospheric data APIs
- **Correlation Analysis**: Statistical analysis between different variables
- **Clustering**: Grouping of similar events with 3D visualizations
- **Anomaly Detection**: Automatic identification of anomalous events
- **Predictions**: Machine learning models for event prediction

### ğŸš¨ **Alert System**
- **Real-time Alerts**: Notifications for high-intensity events
- **Severity Classification**: High, Medium, Low
- **Alert Dashboard**: Dedicated interface for management

### ğŸ› ï¸ **Interface Technologies**
- **REST API**: Complete interface for system interaction
- **WebSockets**: Real-time updates (planned)
- **Database**: Persistent storage with PostgreSQL

## ğŸ› ï¸ Technologies

- **Python 3.11**
- **FastAPI** - Modern web framework
- **PostgreSQL** - Relational database
- **SQLAlchemy** - Python ORM
- **Docker & Docker Compose** - Containerization
- **Pandas & NumPy** - Data analysis
- **Scikit-learn** - Machine Learning
- **Matplotlib & Seaborn** - Visualization
- **PgAdmin** - Database administration interface

## ğŸ“‹ Prerequisites

- Docker Desktop
- Docker Compose
- PowerShell (Windows)

## ğŸƒâ€â™‚ï¸ How to Run

### Option 1: PowerShell Script (Recommended)
```powershell
# Start all services
.\scripts\start.ps1

# Stop all services
.\scripts\stop.ps1
```

### Option 2: Manual Docker Compose
```bash
# Start services
docker-compose up --build -d

# Stop services
docker-compose down

# View logs
docker-compose logs -f app
```

### Option 3: Local Streamlit
```powershell
# Run only Streamlit locally
.\scripts\run_streamlit.ps1
```

### Option 4: Demo Mode
```powershell
# Run demo with sample data
.\scripts\demo.ps1
```

### Option 5: Individual Services
```bash
# Database only
docker-compose up -d db

# FastAPI + Database
docker-compose up -d db app

# All except Grafana
docker-compose up -d db app streamlit pgadmin
```

## ğŸŒ Access Points

After starting the services:

- **ğŸ›ï¸ Main Dashboard**: http://localhost:8000/dashboard
- **ğŸ“Š Streamlit Analytics**: http://localhost:8501
- **ğŸ“ˆ Grafana Monitoring**: http://localhost:3000
  - User: `admin`
  - Password: `admin123`
- **ğŸ“– API Documentation**: http://localhost:8000/docs
- **ğŸ“‹ API Redoc**: http://localhost:8000/redoc
- **ğŸ—„ï¸ PgAdmin**: http://localhost:5050
  - Email: `admin@previsao.com`
  - Password: `admin123`

## ğŸ—„ï¸ Database

### PostgreSQL Connection
- **Host**: localhost
- **Port**: 5432
- **Database**: previsao_solar
- **User**: postgres
- **Password**: postgres123

### Main Tables
- `sep_events` - Solar energetic particle events
- `predictions` - Model-generated predictions
- `alerts` - System alerts
- `model_metrics` - Model performance metrics

## ğŸ“Š API Endpoints

### Data Collection
- `POST /data/collect` - Collect and store data
- `GET /data/events` - List stored events
- `GET /data/high-intensity` - High-intensity events

### Analytics
- `POST /analysis/correlations` - Correlation analysis
- `POST /analysis/clustering` - Event clustering
- `POST /analysis/prediction` - Generate predictions

### Monitoring
- `GET /alerts` - List active alerts
- `GET /health` - Application status

## ğŸ—ï¸ Project Structure

```
solar-impact-insights/
â”œâ”€â”€ app/                    # Main application
â”‚   â”œâ”€â”€ main.py            # Entry point
â”‚   â””â”€â”€ api.py             # FastAPI routes
â”œâ”€â”€ domain/                # Domain entities
â”‚   â””â”€â”€ entities.py        # Data classes
â”œâ”€â”€ use_cases/            # Use cases
â”‚   â”œâ”€â”€ analysis.py       # Statistical analysis
â”‚   â””â”€â”€ alerts.py         # Alert system
â”œâ”€â”€ infrastructure/       # Infrastructure
â”‚   â”œâ”€â”€ data_collection.py # Data collection
â”‚   â”œâ”€â”€ visualization.py   # Visualizations
â”‚   â””â”€â”€ database/         # Database configuration
â”‚       â”œâ”€â”€ models.py     # SQLAlchemy models
â”‚       â””â”€â”€ repository.py # Repositories
â”œâ”€â”€ adapters/             # Adapters
â”‚   â””â”€â”€ data_adapter.py   # Data integration
â”œâ”€â”€ data/                 # Data files
â”‚   â””â”€â”€ real_solar_data.csv # Solar event dataset
â”œâ”€â”€ sql/                  # SQL scripts
â”‚   â””â”€â”€ init.sql          # Database initialization
â”œâ”€â”€ scripts/              # Utility scripts
â”‚   â”œâ”€â”€ start.ps1         # Start services
â”‚   â”œâ”€â”€ stop.ps1          # Stop services
â”‚   â”œâ”€â”€ run_streamlit.ps1 # Run Streamlit locally
â”‚   â”œâ”€â”€ populate_database.py # Database population
â”‚   â”œâ”€â”€ collect_real_data.py # Real data collection
â”‚   â””â”€â”€ demo.ps1          # Demo script
â”œâ”€â”€ static/               # Static web assets
â”‚   â”œâ”€â”€ dashboard.css     # Dashboard styles
â”‚   â””â”€â”€ dashboard.js      # Dashboard JavaScript
â”œâ”€â”€ templates/            # HTML templates
â”‚   â””â”€â”€ dashboard.html    # Main dashboard template
â”œâ”€â”€ grafana/              # Grafana configuration
â”‚   â””â”€â”€ dashboard.json    # Grafana dashboard config
â”œâ”€â”€ logs/                 # Application logs
â”œâ”€â”€ streamlit_app.py      # Streamlit application
â”œâ”€â”€ demo_api.py          # API demonstration script
â”œâ”€â”€ docker-compose.yml    # Docker orchestration
â”œâ”€â”€ Dockerfile           # Application image
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ .env                 # Environment variables
â”œâ”€â”€ .gitignore           # Git ignore rules
â””â”€â”€ README.md            # Project documentation
```

## ğŸ”§ Development

### Local Environment
```bash
# Install dependencies
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env

# Run database only
docker-compose up -d db

# Run local application
python app/main.py

# Run Streamlit locally
python streamlit_app.py
```

### Data Management
```powershell
# Populate database with sample data
python scripts/populate_database.py

# Collect real solar data
python scripts/collect_real_data.py

# Quick data collection
python scripts/quick_collect.py
```

### Debugging
```bash
# View application logs
docker-compose logs -f app

# View database logs
docker-compose logs -f db

# Access application container
docker-compose exec app bash

# Access database
docker-compose exec db psql -U postgres -d previsao_solar
```

## ğŸ“ˆ Usage Example

1. **Start the services**:
   ```powershell
   .\scripts\start.ps1
   ```

2. **Access the dashboard**: http://localhost:8000/dashboard

3. **Collect data**:
   - Click "Collect Mock Data"

4. **Run analyses**:
   - "Correlation Analysis"
   - "Clustering"
   - "Generate Predictions"

5. **Monitor**:
   - "View Alerts"
   - "High-Intensity Events"

## ğŸš¨ Alerts and Monitoring

The system has automatic alerts for:
- High-intensity events (SEP > 5.0)
- Data anomalies detected
- Critical event predictions

## ğŸ“ Logs

Logs are stored in:
- Container: `/app/logs/`
- Local: `./logs/`

## ğŸ¤ Contributing

1. Fork the project
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“„ License

This project is under the MIT license.

## ğŸ†˜ Support

For issues or questions:
1. Check logs: `docker-compose logs -f`
2. Restart services: `.\scripts\stop.ps1` and `.\scripts\start.ps1`
3. Verify all ports are available

## ğŸ”„ Updates

To update the system:
```powershell
# Stop services
.\scripts\stop.ps1

# Rebuild
docker-compose build --no-cache

# Start
.\scripts\start.ps1
```
