#!/usr/bin/env python3
"""
Script para popular o banco de dados com os dados coletados
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import sys
import time

# Adicionar o diretÃ³rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from sqlalchemy import create_engine, text
    from sqlalchemy.orm import sessionmaker
    from infrastructure.database.models import SEPEvent
    from domain.entities import SolarEvent
    from use_cases.analysis import SolarAnalysisService
    from use_cases.alerts import AlertService
    print("âœ… ImportaÃ§Ãµes realizadas com sucesso")
except ImportError as e:
    print(f"âŒ Erro de importaÃ§Ã£o: {e}")
    print("Instalando dependÃªncias...")
    import subprocess
    subprocess.run([sys.executable, "-m", "pip", "install", "sqlalchemy", "psycopg2-binary", "pandas", "numpy", "scikit-learn"], 
                   check=True)

def get_database_connection():
    """Conecta ao banco de dados"""
    print("ğŸ”Œ Conectando ao banco de dados...")
    
    # String de conexÃ£o para PostgreSQL
    DATABASE_URL = "postgresql://solar_user:solar_pass@localhost:5432/solar_db"
    
    try:
        engine = create_engine(DATABASE_URL)
        # Testar conexÃ£o
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1"))
            print("âœ… ConexÃ£o com banco estabelecida")
        return engine
    except Exception as e:
        print(f"âŒ Erro ao conectar com banco: {e}")
        print("ğŸ”„ Tentando aguardar e reconectar...")
        time.sleep(10)
        try:
            engine = create_engine(DATABASE_URL)
            with engine.connect() as conn:
                result = conn.execute(text("SELECT 1"))
                print("âœ… ConexÃ£o estabelecida apÃ³s retry")
            return engine
        except Exception as e2:
            print(f"âŒ Falha definitiva na conexÃ£o: {e2}")
            return None

def load_data():
    """Carrega dados do arquivo CSV"""
    print("ğŸ“‚ Carregando dados do arquivo...")
    
    file_path = 'data/real_solar_data.csv'
    
    if not os.path.exists(file_path):
        print(f"âŒ Arquivo nÃ£o encontrado: {file_path}")
        print("Execute primeiro: python scripts/quick_collect.py")
        return None
    
    try:
        df = pd.read_csv(file_path)
        df['datetime'] = pd.to_datetime(df['datetime'])
        print(f"âœ… Dados carregados: {len(df):,} registros")
        return df
    except Exception as e:
        print(f"âŒ Erro ao carregar dados: {e}")
        return None

def populate_database(engine, df):
    """Popula o banco de dados"""
    print("ğŸ’¾ Populando banco de dados...")
    
    try:
        # Limpar tabela existente
        with engine.connect() as conn:
            conn.execute(text("DELETE FROM sep_events"))
            conn.commit()
            print("ğŸ—‘ï¸ Dados antigos removidos")
        
        # Preparar dados para inserÃ§Ã£o
        df_insert = df.copy()
        df_insert = df_insert.rename(columns={
            'datetime': 'timestamp',
            'sep_intensity': 'intensity',
            'kp_index': 'kp_index',
            'solar_flux': 'solar_flux',
            'sunspot_number': 'sunspot_count',
            'aurora_activity': 'aurora_intensity',
            'cosmic_ray_count': 'cosmic_ray_intensity'
        })
        
        # Adicionar colunas necessÃ¡rias
        df_insert['event_type'] = 'SEP'
        df_insert['severity'] = df_insert['intensity'].apply(lambda x: 
            'HIGH' if x > 7 else 'MEDIUM' if x > 4 else 'LOW')
        df_insert['location'] = 'GLOBAL'
        
        # Selecionar apenas as colunas que existem na tabela
        columns_to_insert = [
            'timestamp', 'event_type', 'intensity', 'severity', 'location',
            'kp_index', 'solar_flux', 'sunspot_count', 'aurora_intensity', 
            'cosmic_ray_intensity', 'temperature', 'ice_extent', 'ozone_level'
        ]
        
        df_final = df_insert[columns_to_insert]
        
        # Inserir em batches
        batch_size = 1000
        total_batches = len(df_final) // batch_size + 1
        
        for i in range(0, len(df_final), batch_size):
            batch = df_final.iloc[i:i+batch_size]
            batch.to_sql('sep_events', engine, if_exists='append', index=False)
            batch_num = (i // batch_size) + 1
            print(f"ğŸ“¦ Batch {batch_num}/{total_batches} inserido ({len(batch)} registros)")
        
        print(f"âœ… {len(df_final):,} registros inseridos com sucesso")
        
        # Verificar inserÃ§Ã£o
        with engine.connect() as conn:
            result = conn.execute(text("SELECT COUNT(*) FROM sep_events"))
            count = result.scalar()
            print(f"ğŸ” VerificaÃ§Ã£o: {count:,} registros na tabela")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro ao popular banco: {e}")
        return False

def generate_alerts(engine):
    """Gera alertas baseados nos dados"""
    print("ğŸš¨ Gerando alertas...")
    
    try:
        with engine.connect() as conn:
            # Buscar eventos de alta intensidade
            high_intensity_query = text("""
                SELECT COUNT(*) FROM sep_events 
                WHERE intensity > 7 AND timestamp > NOW() - INTERVAL '7 days'
            """)
            result = conn.execute(high_intensity_query)
            high_events = result.scalar()
            
            print(f"ğŸ”´ Eventos de alta intensidade (Ãºltimos 7 dias): {high_events}")
            
            # Buscar tendÃªncia recente
            trend_query = text("""
                SELECT AVG(intensity) as avg_intensity 
                FROM sep_events 
                WHERE timestamp > NOW() - INTERVAL '24 hours'
            """)
            result = conn.execute(trend_query)
            avg_intensity = result.scalar() or 0
            
            print(f"ğŸ“ˆ Intensidade mÃ©dia (Ãºltimas 24h): {avg_intensity:.2f}")
            
            if avg_intensity > 5:
                print("âš ï¸ ALERTA: Atividade solar elevada detectada!")
            else:
                print("âœ… Atividade solar dentro do normal")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erro ao gerar alertas: {e}")
        return False

def main():
    """FunÃ§Ã£o principal"""
    print("ğŸš€ POPULANDO BANCO DE DADOS")
    print("=" * 50)
    
    # Conectar ao banco
    engine = get_database_connection()
    if not engine:
        print("âŒ NÃ£o foi possÃ­vel conectar ao banco. Verifique se o Docker estÃ¡ rodando.")
        return False
    
    # Carregar dados
    df = load_data()
    if df is None:
        return False
    
    # Popular banco
    if not populate_database(engine, df):
        return False
    
    # Gerar alertas
    generate_alerts(engine)
    
    print("\n" + "=" * 50)
    print("ğŸ‰ POPULAÃ‡ÃƒO DO BANCO CONCLUÃDA!")
    print("\nğŸŒ ACESSE O DASHBOARD:")
    print("ğŸ“Š Streamlit: http://localhost:8501")
    print("ğŸ“ˆ Grafana: http://localhost:3000")
    print("ğŸ—„ï¸ PgAdmin: http://localhost:5050")
    
    print("\nğŸ“Š ESTATÃSTICAS DOS DADOS:")
    print(f"ğŸ“… PerÃ­odo: {df['datetime'].min()} atÃ© {df['datetime'].max()}")
    print(f"ğŸ“Š Total de registros: {len(df):,}")
    print(f"ğŸ”´ Eventos alta intensidade: {len(df[df['sep_intensity'] > 7]):,}")
    print(f"ğŸŸ¡ Eventos mÃ©dia intensidade: {len(df[(df['sep_intensity'] > 4) & (df['sep_intensity'] <= 7)]):,}")
    print(f"ğŸŸ¢ Eventos baixa intensidade: {len(df[df['sep_intensity'] <= 4]):,}")
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)
